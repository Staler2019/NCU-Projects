{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd003fdeaf8a03935a32ca4d1c8d8063f7bb894f5c3a4a58b053fc2a30007e4d3d9",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2450\n1700\n"
     ]
    }
   ],
   "source": [
    "# load data to \n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_dataset = \"./handwrite__detect/train_image\"\n",
    "test_dataset = \"./handwrite__detect/test_image\"\n",
    "\n",
    "def loadData(src):\n",
    "    x = np.empty([0, 28, 28, 1])\n",
    "    y = np.empty([0])\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        root_split = root.split(\"\\\\\")\n",
    "\n",
    "        if len(root_split) == 3:\n",
    "            # print(root)\n",
    "            for f in files:\n",
    "                in_file = os.path.join(root, f)\n",
    "                y = np.append(y, [root_split[2]], axis=0)  # index\n",
    "                # image only black(255, 255, 255) or white(0, 0, 0), so just choose the first number\n",
    "                np_img = img.imread(in_file)[:,:,0].reshape([1, 28, 28, 1])  \n",
    "                x = np.append(x, np_img, axis=0)  # image\n",
    "    return x, y\n",
    "    \n",
    "# x: image list, # y: number list\n",
    "x_train, y_train = loadData(train_dataset)\n",
    "x_test, y_test = loadData(test_dataset)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 12, 12, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1179776   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 1,199,882\nTrainable params: 1,199,882\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make a CNN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam  # SGD\n",
    "\n",
    "# shape = [-1, 28, 28, 1] <=> [-1, 784]\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # -- ways one -- acc:0.93\n",
    "        # Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        # MaxPooling2D((2, 2)),\n",
    "        # Flatten(),\n",
    "        # Dense(100, activation='relu'),\n",
    "        # Dense(10, activation='softmax')\n",
    "        # -- ways two -- acc:0.95\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 20s 186ms/step - loss: 1.9690 - accuracy: 0.3207 - val_loss: 0.7730 - val_accuracy: 0.7800\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 3s 146ms/step - loss: 0.6980 - accuracy: 0.7818 - val_loss: 0.4573 - val_accuracy: 0.8565\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 3s 145ms/step - loss: 0.3708 - accuracy: 0.8849 - val_loss: 0.3629 - val_accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.2455 - accuracy: 0.9215 - val_loss: 0.2912 - val_accuracy: 0.9012\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.1763 - accuracy: 0.9476 - val_loss: 0.2705 - val_accuracy: 0.9059\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.1405 - accuracy: 0.9534 - val_loss: 0.2500 - val_accuracy: 0.9112\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.1315 - accuracy: 0.9572 - val_loss: 0.2190 - val_accuracy: 0.9271\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.0956 - accuracy: 0.9726 - val_loss: 0.2063 - val_accuracy: 0.9288\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 0.2072 - val_accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 3s 149ms/step - loss: 0.0716 - accuracy: 0.9801 - val_loss: 0.2021 - val_accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "model.save(\"chinese_number_identification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2021 - accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "# answer viewing\n",
    "score = model.evaluate(x_test, y_test)"
   ]
  }
 ]
}