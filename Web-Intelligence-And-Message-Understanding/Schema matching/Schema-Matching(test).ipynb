{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-18T16:38:38.86135Z","iopub.status.busy":"2022-04-18T16:38:38.861114Z","iopub.status.idle":"2022-04-18T16:38:51.811993Z","shell.execute_reply":"2022-04-18T16:38:51.810548Z","shell.execute_reply.started":"2022-04-18T16:38:38.861284Z"},"trusted":true},"outputs":[],"source":["%pip install opencc-python-reimplemented"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:38:51.81438Z","iopub.status.busy":"2022-04-18T16:38:51.81411Z","iopub.status.idle":"2022-04-18T16:38:57.411425Z","shell.execute_reply":"2022-04-18T16:38:57.410636Z","shell.execute_reply.started":"2022-04-18T16:38:51.814344Z"},"trusted":true},"outputs":[],"source":["import time\n","import os\n","import re\n","from transformers import BertTokenizer, BertModel\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from opencc import OpenCC\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:38:57.413392Z","iopub.status.busy":"2022-04-18T16:38:57.413103Z","iopub.status.idle":"2022-04-18T16:39:01.954159Z","shell.execute_reply":"2022-04-18T16:39:01.953479Z","shell.execute_reply.started":"2022-04-18T16:38:57.413313Z"},"trusted":true},"outputs":[],"source":["# same above\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dataset_dir = \"./Data\"\n","model_name = \"bert-base-multilingual-cased\"\n","model_loc = \"./bert-model/bert-model.pt\"\n","model_classes = 70  # len(dataset)\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","ans_dir = \"./Result\"\n","cc = OpenCC(\"s2t\")\n","MAX_COMPARED_WORDS = 200\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:39:01.956513Z","iopub.status.busy":"2022-04-18T16:39:01.956157Z","iopub.status.idle":"2022-04-18T16:39:01.963838Z","shell.execute_reply":"2022-04-18T16:39:01.962949Z","shell.execute_reply.started":"2022-04-18T16:39:01.956459Z"},"trusted":true},"outputs":[],"source":["# same above\n","class BertClassifier(nn.Module):\n","    def __init__(self, num_class, model_name):\n","        super(BertClassifier, self).__init__()\n","        self.num_class = num_class\n","        self.model_name = model_name\n","\n","        self.bert = BertModel.from_pretrained(self.model_name)\n","        self.dense = nn.Linear(self.bert.config.hidden_size, self.num_class)\n","\n","    # Define how your model pass data\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        # keys(): ['last_hidden_state', 'pooler_output']\n","\n","        outputs = outputs[\"pooler_output\"]  # shape: (batch, hidden_size)\n","        logits = self.dense(outputs)  # shape: (batch, num_class)\n","\n","        return logits, F.softmax(logits, dim=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:39:01.965498Z","iopub.status.busy":"2022-04-18T16:39:01.965151Z","iopub.status.idle":"2022-04-18T16:39:43.84297Z","shell.execute_reply":"2022-04-18T16:39:43.842329Z","shell.execute_reply.started":"2022-04-18T16:39:01.965447Z"},"trusted":true},"outputs":[],"source":["# same above\n","# load model\n","model = BertClassifier(model_classes, model_name).to(device)\n","model.load_state_dict(torch.load(model_loc, map_location=device))\n","model.eval()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:39:43.844974Z","iopub.status.busy":"2022-04-18T16:39:43.844489Z","iopub.status.idle":"2022-04-18T16:39:44.58367Z","shell.execute_reply":"2022-04-18T16:39:44.582687Z","shell.execute_reply.started":"2022-04-18T16:39:43.844937Z"},"trusted":true},"outputs":[],"source":["!mkdir Result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:39:44.585973Z","iopub.status.busy":"2022-04-18T16:39:44.585705Z","iopub.status.idle":"2022-04-18T16:39:46.326443Z","shell.execute_reply":"2022-04-18T16:39:46.325611Z","shell.execute_reply.started":"2022-04-18T16:39:44.585938Z"},"trusted":true},"outputs":[],"source":["def get_classifier_val(text):\n","    encoded_input = tokenizer(\n","        text,\n","        padding=\"max_length\",\n","        max_length=256,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","    )\n","\n","    logits, softmaxed = model(\n","        encoded_input[\"input_ids\"].squeeze(dim=1).to(device),\n","        encoded_input[\"attention_mask\"].squeeze(dim=1).to(device),\n","    )\n","\n","    return softmaxed[0].cpu().detach().numpy()\n","\n","\n","def cal_vec(word_list):\n","    _list = []\n","    counter = 0\n","\n","    for word in word_list:\n","        _list.append(get_classifier_val(cc.convert(str(word))))\n","\n","        counter += 1\n","        if counter >= MAX_COMPARED_WORDS:\n","            break\n","\n","    vec = np.mean(np.array(_list), axis=0)\n","\n","    test = np.sum(vec)\n","    test_times = 1 / test\n","    vec *= test_times\n","\n","    return vec\n","\n","\n","def findSuccessPair(df):\n","    x_tags = df.columns\n","    y_tags = df.index\n","    predicted_num = min(len(x_tags), len(y_tags))\n","    pairs = []\n","    ran_x = []\n","    ran_y = []\n","\n","    for _ in range(predicted_num):\n","        max_val = 0\n","        max_x = \"\"\n","        max_y = \"\"\n","\n","        for x in x_tags:  # O(n^2)\n","            if x in ran_x:\n","                continue\n","            for y in y_tags:\n","                if y in ran_y:\n","                    continue\n","\n","                if max_val < df[x][y]:\n","                    max_val = df[x][y]\n","                    max_x = x\n","                    max_y = y\n","        if max_val != 0:\n","            pairs.append((max_x, max_y))\n","            ran_x.append(max_x)\n","            ran_y.append(max_y)\n","\n","    return pairs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-18T16:41:55.0093Z","iopub.status.busy":"2022-04-18T16:41:55.008762Z","iopub.status.idle":"2022-04-18T16:41:55.024816Z","shell.execute_reply":"2022-04-18T16:41:55.023699Z","shell.execute_reply.started":"2022-04-18T16:41:55.009262Z"},"trusted":true},"outputs":[],"source":["for (dirpath, dirnames, filenames) in os.walk(dataset_dir):\n","    if \"mapping.txt\" in filenames:\n","        print(\"accessing...\", dirpath)\n","\n","        mapping = []\n","\n","        with open(os.path.join(dirpath, \"mapping.txt\"), \"r\", encoding=\"UTF-8\") as f:\n","            for line in f.readlines():\n","                words = line.split(\",\")\n","                mapping.append((words[0][1:], words[1].split(\"\\n\")[0][1:-1]))\n","\n","        dict1 = {}\n","        dict2 = {}\n","\n","        # Table1.csv\n","        df1 = pd.read_csv(os.path.join(dirpath, \"Table1.csv\"), low_memory=False)\n","        df1 = df1.dropna(how=\"all\").fillna(\"\")\n","        # Table2.csv\n","        df2 = pd.read_csv(os.path.join(dirpath, \"Table2.csv\"), low_memory=False)\n","        df2 = df2.dropna(how=\"all\").fillna(\"\")\n","\n","        # my generated pd\n","        cols = []\n","        for col in df1.columns:\n","            cols.append(col)\n","\n","        rows = []\n","        row_index = []\n","\n","        for row in df2.columns:\n","            a_row = []\n","\n","            row_index.append(row)\n","            for col in df1.columns:\n","                if col not in dict1.keys():\n","                    vec = cal_vec(df1[col])\n","                    dict1[col] = vec\n","                if row not in dict2.keys():\n","                    vec = cal_vec(df2[row])\n","                    dict2[row] = vec\n","                val = np.dot(dict1[col], dict2[row])\n","                a_row.append(val)\n","            rows.append(a_row)\n","\n","        df = pd.DataFrame(rows, columns=cols, index=row_index)\n","\n","        # write pair mapping\n","        if len(rows) < 10:\n","            base = len(rows)\n","            for i in range(base, 10):\n","                rows.append([\"\" for _ in range(len(cols))])\n","                row_index.append(\"\")\n","\n","        cols.append(\"\")\n","        cols.append(\"最佳配對\")\n","        rows[0].append(\"\")\n","        rows[0].append(\"Table1\")\n","        rows[1].append(\"\")\n","        rows[1].append(\"Table2\")\n","        rows[3].append(\"\")\n","        rows[3].append(\"successful pair\")\n","        rows[4].append(\"\")\n","        rows[4].append(\"Table1\")\n","        rows[5].append(\"\")\n","        rows[5].append(\"Table2\")\n","        rows[7].append(\"\")\n","        rows[7].append(\"failed pair\")\n","        rows[8].append(\"\")\n","        rows[8].append(\"Table1\")\n","        rows[9].append(\"\")\n","        rows[9].append(\"Table2\")\n","\n","        ## alg to find pair: get col_name and row_name\n","        pairs = findSuccessPair(df)\n","\n","        succ_pc = 0\n","        fail_pc = 0\n","        for i, (col_name, row_name) in enumerate(pairs):\n","            # appendSuccessPair(): row[1], row[2], col_name, row_name, col_tag(string, f\"pair_{index}\")\n","            cols.append(f\"pair_{i + 1}\")\n","            rows[0].append(col_name)\n","            rows[1].append(row_name)\n","\n","            if (col_name, row_name) in mapping:\n","                succ_pc += 1\n","                rows[3].append(f\"pair_{succ_pc}\")\n","                rows[4].append(col_name)\n","                rows[5].append(row_name)\n","            else:\n","                fail_pc += 1\n","                rows[7].append(f\"pair_{fail_pc}\")\n","                rows[8].append(col_name)\n","                rows[9].append(row_name)\n","\n","        df = pd.DataFrame(rows, columns=cols, index=row_index)\n","        df.to_csv(\n","            os.path.join(\n","                ans_dir,\n","                \"result_{}.csv\".format(\n","                    re.search(\"\\d+$\", dirpath.split(\"\\\\\")[-1]).group(0)\n","                ),\n","            )\n","        )\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
